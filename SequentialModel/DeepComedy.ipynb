{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepComedy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8xB0z_hYbG"
      },
      "source": [
        "# DeepComedy: AI Generated Divine Comedy\n",
        "\n",
        "Author: **Alessandro Pavesi, Federico Battistella**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncDUryHdqckI"
      },
      "source": [
        "This Notebook contains a **text generator RNN** that was trained on the **Divina Commedia** (the *Divine Comedy*) by **Dante Alighieri**. \n",
        "\n",
        "It's structure is extremely complex: the poem is composed by three Cantiche, each Cantica has 33 Terzine, each Terzina is composed by three verses, each verse is composed of 11 syllables, and its rhymes follow an **A-B-A-B-C-B-C** structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8FnhxiWY_Y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5240bdce-c42a-4d97-c21a-e2800608be24"
      },
      "source": [
        "import time\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Attention, Flatten, Input\n",
        "from tensorflow.keras.activations import elu, relu, softmax\n",
        "from tensorflow.keras.metrics import categorical_accuracy, sparse_categorical_crossentropy, categorical_crossentropy\n",
        "\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVW2XbaZ_GGM"
      },
      "source": [
        "# Preliminaries Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkhp6e4Sztim"
      },
      "source": [
        "## Import and initial cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5YiWU0daYkT"
      },
      "source": [
        "# Read the Divina Commedia\n",
        "with open( \"DivinaCommedia.txt\", 'r', encoding=\"utf8\") as file:\n",
        "    divina_commedia = file.read()\n",
        "\n",
        "# Replace rare characters\n",
        "divina_commedia = divina_commedia.replace(\"ä\", \"a\")\n",
        "divina_commedia = divina_commedia.replace(\"é\", \"è\")\n",
        "divina_commedia = divina_commedia.replace(\"ë\", \"è\")\n",
        "divina_commedia = divina_commedia.replace(\"Ë\", \"E\")\n",
        "divina_commedia = divina_commedia.replace(\"ï\", \"i\")\n",
        "divina_commedia = divina_commedia.replace(\"Ï\", \"I\")\n",
        "divina_commedia = divina_commedia.replace(\"ó\", \"ò\")\n",
        "divina_commedia = divina_commedia.replace(\"ö\", \"o\")\n",
        "divina_commedia = divina_commedia.replace(\"ü\", \"u\")\n",
        "\n",
        "divina_commedia = divina_commedia.replace(\"(\", \"-\")\n",
        "divina_commedia = divina_commedia.replace(\")\", \"-\")\n",
        "\n",
        "divina_commedia = re.sub(r'[0-9]+', '', divina_commedia)\n",
        "divina_commedia = re.sub(r'\\[.*\\r?\\n', '', divina_commedia)\n",
        "divina_commedia = re.sub(r'.*Canto.*\\r?\\n', '', divina_commedia)\n",
        "\n",
        "# divina_commedia = divina_commedia.replace(\" \\n\", \"\\n\")  # with this i lose the \"terzina\": results are not so exciting\n",
        "#divina_commedia = divina_commedia.replace(\" \\n\", \"<eot>\")  # end of terzina\n",
        "#divina_commedia = divina_commedia.replace(\"\\n\", \"<eor>\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynI7x9Rp7yQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3780e503-4b8b-4a54-fec4-d71dfa076709"
      },
      "source": [
        "print(divina_commedia[1:1000])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NFERNO\n",
            "\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita. \n",
            "\n",
            "Ahi quanto a dir qual era è cosa dura\n",
            "esta selva selvaggia e aspra e forte\n",
            "che nel pensier rinova la paura! \n",
            "\n",
            "Tant'è amara che poco è più morte;\n",
            "ma per trattar del ben ch'i' vi trovai,\n",
            "dirò de l'altre cose ch'i' v' ho scorte. \n",
            "\n",
            "Io non so ben ridir com'i' v'intrai,\n",
            "tant'era pien di sonno a quel punto\n",
            "che la verace via abbandonai. \n",
            "\n",
            "Ma poi ch'i' fui al piè d'un colle giunto,\n",
            "là dove terminava quella valle\n",
            "che m'avea di paura il cor compunto, \n",
            "\n",
            "guardai in alto e vidi le sue spalle\n",
            "vestite già de' raggi del pianeta\n",
            "che mena dritto altrui per ogne calle. \n",
            "\n",
            "Allor fu la paura un poco queta,\n",
            "che nel lago del cor m'era durata\n",
            "la notte ch'i' passai con tanta pieta. \n",
            "\n",
            "E come quei che con lena affannata,\n",
            "uscito fuor del pelago a la riva,\n",
            "si volge a l'acqua perigliosa e guata, \n",
            "\n",
            "così l'animo mio, ch'ancor fuggiva,\n",
            "si volse a retro a rimirar lo passo\n",
            "che non lasciò già mai persona viva\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILphRXIXaYrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd2aee2-4a6b-4222-82a0-6c1bb4ddf8f5"
      },
      "source": [
        "# Check lenght of text\n",
        "print(len(divina_commedia))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "534049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZw3-Joyhg5l"
      },
      "source": [
        "## Vocabulary and Char2Idx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwvjeLGWAVE4"
      },
      "source": [
        "# Store unique characters into a dict with numerical encoding\n",
        "unique_chars = list(set(divina_commedia))\n",
        "unique_chars.sort()  # to make sure you get the same encoding at each run\n",
        "\n",
        "# Store them in a dict, associated with a numerical index\n",
        "char2idx = { char[1]: char[0] for char in enumerate(unique_chars) }\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkXOJ3LGAVCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f03ead-42a0-4aab-c232-96bec2904561"
      },
      "source": [
        "print(len(char2idx))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sieJxDhAU_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9b5b59-6a1e-4861-f50d-f1529ff14ff2"
      },
      "source": [
        "char2idx"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " \"'\": 4,\n",
              " ',': 5,\n",
              " '-': 6,\n",
              " '.': 7,\n",
              " ':': 8,\n",
              " ';': 9,\n",
              " '?': 10,\n",
              " 'A': 11,\n",
              " 'B': 12,\n",
              " 'C': 13,\n",
              " 'D': 14,\n",
              " 'E': 15,\n",
              " 'F': 16,\n",
              " 'G': 17,\n",
              " 'H': 18,\n",
              " 'I': 19,\n",
              " 'L': 20,\n",
              " 'M': 21,\n",
              " 'N': 22,\n",
              " 'O': 23,\n",
              " 'P': 24,\n",
              " 'Q': 25,\n",
              " 'R': 26,\n",
              " 'S': 27,\n",
              " 'T': 28,\n",
              " 'U': 29,\n",
              " 'V': 30,\n",
              " 'Z': 31,\n",
              " 'a': 32,\n",
              " 'b': 33,\n",
              " 'c': 34,\n",
              " 'd': 35,\n",
              " 'e': 36,\n",
              " 'f': 37,\n",
              " 'g': 38,\n",
              " 'h': 39,\n",
              " 'i': 40,\n",
              " 'j': 41,\n",
              " 'l': 42,\n",
              " 'm': 43,\n",
              " 'n': 44,\n",
              " 'o': 45,\n",
              " 'p': 46,\n",
              " 'q': 47,\n",
              " 'r': 48,\n",
              " 's': 49,\n",
              " 't': 50,\n",
              " 'u': 51,\n",
              " 'v': 52,\n",
              " 'x': 53,\n",
              " 'y': 54,\n",
              " 'z': 55,\n",
              " 'È': 56,\n",
              " 'à': 57,\n",
              " 'è': 58,\n",
              " 'ì': 59,\n",
              " 'ò': 60,\n",
              " 'ù': 61}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2H5G86HhyvE"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk_BqFK4AU9H"
      },
      "source": [
        "def numerical_encoding(text, char_dict):\n",
        "    \"\"\" Text to list of chars, to np.array of numerical idx \"\"\"\n",
        "    chars_list = [ char for char in text ]\n",
        "    chars_list = [ char_dict[char] for char in chars_list ]\n",
        "    chars_list = np.array(chars_list)\n",
        "    return chars_list\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7JpYN9LAU7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a067f70-9558-49dd-9ef7-4b476c2281a7"
      },
      "source": [
        "# Let's see what the first line will look like\n",
        "print(\"{}\".format(divina_commedia[276:511]))\n",
        "print(\"\\nbecomes:\")\n",
        "print(numerical_encoding(divina_commedia[276:511], char2idx))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "del ben ch'i' vi trovai,\n",
            "dirò de l'altre cose ch'i' v' ho scorte. \n",
            "\n",
            "Io non so ben ridir com'i' v'intrai,\n",
            "tant'era pien di sonno a quel punto\n",
            "che la verace via abbandonai. \n",
            "\n",
            "Ma poi ch'i' fui al piè d'un colle giunto,\n",
            "là dove terminava q\n",
            "\n",
            "becomes:\n",
            "[35 36 42  1 33 36 44  1 34 39  4 40  4  1 52 40  1 50 48 45 52 32 40  5\n",
            "  0 35 40 48 60  1 35 36  1 42  4 32 42 50 48 36  1 34 45 49 36  1 34 39\n",
            "  4 40  4  1 52  4  1 39 45  1 49 34 45 48 50 36  7  1  0  0 19 45  1 44\n",
            " 45 44  1 49 45  1 33 36 44  1 48 40 35 40 48  1 34 45 43  4 40  4  1 52\n",
            "  4 40 44 50 48 32 40  5  0 50 32 44 50  4 36 48 32  1 46 40 36 44  1 35\n",
            " 40  1 49 45 44 44 45  1 32  1 47 51 36 42  1 46 51 44 50 45  0 34 39 36\n",
            "  1 42 32  1 52 36 48 32 34 36  1 52 40 32  1 32 33 33 32 44 35 45 44 32\n",
            " 40  7  1  0  0 21 32  1 46 45 40  1 34 39  4 40  4  1 37 51 40  1 32 42\n",
            "  1 46 40 58  1 35  4 51 44  1 34 45 42 42 36  1 38 40 51 44 50 45  5  0\n",
            " 42 57  1 35 45 52 36  1 50 36 48 43 40 44 32 52 32  1 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqALeTUmnl0X"
      },
      "source": [
        "# Processing Data for DanteRNN\n",
        "\n",
        "We need to generate the input for our RNN, the input sequence and an output sequence needs to be of equal length, in which each character is shifted left of one position.\n",
        "\n",
        "For example, the first verse:\n",
        "\n",
        "> Nel mezzo del cammin di nostra vita\n",
        "\n",
        "would be translated in a train sequence as:\n",
        "\n",
        "`Nel mezzo del cammin di nostra vit`\n",
        "\n",
        "be associated with the target sequence:\n",
        "\n",
        "`el mezzo del cammin di nostra vita`\n",
        "\n",
        "The following function is a preparatory step for that. More generally, given a sequence:\n",
        "\n",
        "```\n",
        "A B C D E F G H I\n",
        "```\n",
        "\n",
        "and assuming input sequences of length 5, it will generate a matrix like:\n",
        "\n",
        "```\n",
        "A B C D E\n",
        "B C D E F\n",
        "C D E F G\n",
        "D E F G H\n",
        "E F G H I\n",
        "```\n",
        "\n",
        "The split between train and target sets will be as:\n",
        "\n",
        "```\n",
        " Train:           Target:\n",
        "                 \n",
        "A B C D E        B C D E F\n",
        "B C D E F        C D E F G\n",
        "C D E F G        D E F G H\n",
        "D E F G H        E F G H I\n",
        "                 \n",
        "```\n",
        "\n",
        "Train and target sets are fundamentally the same matrix, with the train having the last row removed, and the target set having the first removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWcZzOJdG6X9"
      },
      "source": [
        "# Apply it on the whole Comedy\n",
        "encoded_text = numerical_encoding(divina_commedia, char2idx)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foyC3ZnGgKLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f06d1a-6c61-4e9a-8d12-d8f6cc5d8250"
      },
      "source": [
        "print(encoded_text[311:600])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[32 42 50 48 36  1 34 45 49 36  1 34 39  4 40  4  1 52  4  1 39 45  1 49\n",
            " 34 45 48 50 36  7  1  0  0 19 45  1 44 45 44  1 49 45  1 33 36 44  1 48\n",
            " 40 35 40 48  1 34 45 43  4 40  4  1 52  4 40 44 50 48 32 40  5  0 50 32\n",
            " 44 50  4 36 48 32  1 46 40 36 44  1 35 40  1 49 45 44 44 45  1 32  1 47\n",
            " 51 36 42  1 46 51 44 50 45  0 34 39 36  1 42 32  1 52 36 48 32 34 36  1\n",
            " 52 40 32  1 32 33 33 32 44 35 45 44 32 40  7  1  0  0 21 32  1 46 45 40\n",
            "  1 34 39  4 40  4  1 37 51 40  1 32 42  1 46 40 58  1 35  4 51 44  1 34\n",
            " 45 42 42 36  1 38 40 51 44 50 45  5  0 42 57  1 35 45 52 36  1 50 36 48\n",
            " 43 40 44 32 52 32  1 47 51 36 42 42 32  1 52 32 42 42 36  0 34 39 36  1\n",
            " 43  4 32 52 36 32  1 35 40  1 46 32 51 48 32  1 40 42  1 34 45 48  1 34\n",
            " 45 43 46 51 44 50 45  5  1  0  0 38 51 32 48 35 32 40  1 40 44  1 32 42\n",
            " 50 45  1 36  1 52 40 35 40  1 42 36  1 49 51 36  1 49 46 32 42 42 36  0\n",
            " 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t41gYByxAU4B"
      },
      "source": [
        "def get_text_matrix(sequence, len_input):\n",
        "    \n",
        "    # create empty matrix\n",
        "    X = np.empty((len(sequence)-len_input, len_input))\n",
        "    \n",
        "    # fill each row/time window from input sequence\n",
        "    for i in range(X.shape[0]):\n",
        "        X[i,:] = sequence[i : i+len_input]\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eazAAQiAk0i"
      },
      "source": [
        "len_text = 150\n",
        "text_matrix = get_text_matrix(encoded_text, len_text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KonviQjQAk40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af35e83-9c8c-4902-d62d-912e324d2024"
      },
      "source": [
        "print(text_matrix.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(533899, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaVngDG7AkyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccb4c0a-53ca-449e-de5b-5f9570109719"
      },
      "source": [
        "print(\"100th train sequence:\\n\")\n",
        "print(text_matrix[ 100, : ])\n",
        "print(\"\\n\\n100th target sequence:\\n\")\n",
        "print(text_matrix[ 101, : ])\n",
        "print(\"\\n\\n102th target sequence:\\n\")\n",
        "print(text_matrix[ 102, : ])\n",
        "print(\"\\n\\n115th target sequence:\\n\")\n",
        "print(text_matrix[ 180, : ])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100th train sequence:\n",
            "\n",
            "[36. 48. 32.  1. 49. 43. 32. 48. 48. 40. 50. 32.  7.  1.  0.  0. 11. 39.\n",
            " 40.  1. 47. 51. 32. 44. 50. 45.  1. 32.  1. 35. 40. 48.  1. 47. 51. 32.\n",
            " 42.  1. 36. 48. 32.  1. 58.  1. 34. 45. 49. 32.  1. 35. 51. 48. 32.  0.\n",
            " 36. 49. 50. 32.  1. 49. 36. 42. 52. 32.  1. 49. 36. 42. 52. 32. 38. 38.\n",
            " 40. 32.  1. 36.  1. 32. 49. 46. 48. 32.  1. 36.  1. 37. 45. 48. 50. 36.\n",
            "  0. 34. 39. 36.  1. 44. 36. 42.  1. 46. 36. 44. 49. 40. 36. 48.  1. 48.\n",
            " 40. 44. 45. 52. 32.  1. 42. 32.  1. 46. 32. 51. 48. 32.  2.  1.  0.  0.\n",
            " 28. 32. 44. 50.  4. 58.  1. 32. 43. 32. 48. 32.  1. 34. 39. 36.  1. 46.\n",
            " 45. 34. 45.  1. 58.  1.]\n",
            "\n",
            "\n",
            "100th target sequence:\n",
            "\n",
            "[48. 32.  1. 49. 43. 32. 48. 48. 40. 50. 32.  7.  1.  0.  0. 11. 39. 40.\n",
            "  1. 47. 51. 32. 44. 50. 45.  1. 32.  1. 35. 40. 48.  1. 47. 51. 32. 42.\n",
            "  1. 36. 48. 32.  1. 58.  1. 34. 45. 49. 32.  1. 35. 51. 48. 32.  0. 36.\n",
            " 49. 50. 32.  1. 49. 36. 42. 52. 32.  1. 49. 36. 42. 52. 32. 38. 38. 40.\n",
            " 32.  1. 36.  1. 32. 49. 46. 48. 32.  1. 36.  1. 37. 45. 48. 50. 36.  0.\n",
            " 34. 39. 36.  1. 44. 36. 42.  1. 46. 36. 44. 49. 40. 36. 48.  1. 48. 40.\n",
            " 44. 45. 52. 32.  1. 42. 32.  1. 46. 32. 51. 48. 32.  2.  1.  0.  0. 28.\n",
            " 32. 44. 50.  4. 58.  1. 32. 43. 32. 48. 32.  1. 34. 39. 36.  1. 46. 45.\n",
            " 34. 45.  1. 58.  1. 46.]\n",
            "\n",
            "\n",
            "102th target sequence:\n",
            "\n",
            "[32.  1. 49. 43. 32. 48. 48. 40. 50. 32.  7.  1.  0.  0. 11. 39. 40.  1.\n",
            " 47. 51. 32. 44. 50. 45.  1. 32.  1. 35. 40. 48.  1. 47. 51. 32. 42.  1.\n",
            " 36. 48. 32.  1. 58.  1. 34. 45. 49. 32.  1. 35. 51. 48. 32.  0. 36. 49.\n",
            " 50. 32.  1. 49. 36. 42. 52. 32.  1. 49. 36. 42. 52. 32. 38. 38. 40. 32.\n",
            "  1. 36.  1. 32. 49. 46. 48. 32.  1. 36.  1. 37. 45. 48. 50. 36.  0. 34.\n",
            " 39. 36.  1. 44. 36. 42.  1. 46. 36. 44. 49. 40. 36. 48.  1. 48. 40. 44.\n",
            " 45. 52. 32.  1. 42. 32.  1. 46. 32. 51. 48. 32.  2.  1.  0.  0. 28. 32.\n",
            " 44. 50.  4. 58.  1. 32. 43. 32. 48. 32.  1. 34. 39. 36.  1. 46. 45. 34.\n",
            " 45.  1. 58.  1. 46. 40.]\n",
            "\n",
            "\n",
            "115th target sequence:\n",
            "\n",
            "[48. 32.  1. 36.  1. 37. 45. 48. 50. 36.  0. 34. 39. 36.  1. 44. 36. 42.\n",
            "  1. 46. 36. 44. 49. 40. 36. 48.  1. 48. 40. 44. 45. 52. 32.  1. 42. 32.\n",
            "  1. 46. 32. 51. 48. 32.  2.  1.  0.  0. 28. 32. 44. 50.  4. 58.  1. 32.\n",
            " 43. 32. 48. 32.  1. 34. 39. 36.  1. 46. 45. 34. 45.  1. 58.  1. 46. 40.\n",
            " 61.  1. 43. 45. 48. 50. 36.  9.  0. 43. 32.  1. 46. 36. 48.  1. 50. 48.\n",
            " 32. 50. 50. 32. 48.  1. 35. 36. 42.  1. 33. 36. 44.  1. 34. 39.  4. 40.\n",
            "  4.  1. 52. 40.  1. 50. 48. 45. 52. 32. 40.  5.  0. 35. 40. 48. 60.  1.\n",
            " 35. 36.  1. 42.  4. 32. 42. 50. 48. 36.  1. 34. 45. 49. 36.  1. 34. 39.\n",
            "  4. 40.  4.  1. 52.  4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTb_xjIHFMQg"
      },
      "source": [
        "# Custom Loss\n",
        "Evaluate the structure of the rhymes, based on the real scheme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUfoUSUSXjl5"
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "\n",
        "def divide_versi(y):\n",
        "  doppiozero = False\n",
        "\n",
        "  y_divided = [[]]\n",
        "  for ly in y:\n",
        "    ly = int(ly)\n",
        "\n",
        "    # I have to clean the list of punctuation marks,\n",
        "    # in chartoidx means the numbers 1 to 10 inclusive.\n",
        "    if ly in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
        "        continue\n",
        "    else:\n",
        "      # if it is zero it means \\ n so I add a new line\n",
        "      if ly is 0:\n",
        "        if not doppiozero:\n",
        "          y_divided.append([])\n",
        "        doppiozero = True\n",
        "        continue\n",
        "\n",
        "      y_divided[-1].append(ly)\n",
        "      doppiozero = False\n",
        "\n",
        "  if y_divided is not []:\n",
        "    if y[-1] != 0:\n",
        "      # since the last line does not end with 0 it means that it is incomplete and I remove it\n",
        "      y_divided.pop()\n",
        "\n",
        "  # i need to re check because maybe i pop the only one\n",
        "  if len(y_divided) != 0:\n",
        "    if len(y_divided[0]) < 3:\n",
        "      # if the first line is less than 4 I can't do anything about it so I delete it\n",
        "      y_divided.pop(0)\n",
        "\n",
        "  return y_divided\n",
        "\n",
        "def rhymes_extractor(y_divided):\n",
        "  # I extract the rhyme scheme from y\n",
        "  rhymes = []\n",
        "  for i in range(len(y_divided)):\n",
        "    # with the end of the line (last two letters) I check if the other lines\n",
        "    # end with the same letters\n",
        "    vy = y_divided[i]\n",
        "\n",
        "    last_word_1 = vy[-2:]\n",
        "\n",
        "    # ABA BCB CDC\n",
        "\n",
        "    # I have to check if line i rhymes with line i + 2\n",
        "    if i+2 < len(y_divided):\n",
        "      next_vy = y_divided[i+2]\n",
        "      if last_word_1 == next_vy[-2:]:\n",
        "        rhymes.append((i, i+2))\n",
        "    \n",
        "    if i+4 < len(y_divided):\n",
        "      next_vy = y_divided[i+4]\n",
        "      if last_word_1 == next_vy[-2:]:\n",
        "        rhymes.append((i, i+4))\n",
        "\n",
        "  return rhymes\n",
        "\n",
        "\n",
        "def get_custom_loss(x_batch, y_batch):\n",
        "  summed_custom_loss = 0\n",
        "\n",
        "  # max number of rhymes (arbitrary choosen, it's an hyperparameter)\n",
        "  max_rhymes = 4\n",
        "\n",
        "  x_bin_tot = np.ones(shape=(len(x_batch), max_rhymes), dtype='float32')\n",
        "  y_bin_tot = np.ones(shape=(len(x_batch), max_rhymes), dtype='float32')\n",
        "\n",
        "  # iterate over each vector\n",
        "  for v in range(len(x_batch)):\n",
        "    x = x_batch[v]\n",
        "    y = y_batch[v]\n",
        "\n",
        "    # given that the model returns a matrix with shape (len_text, vocab_size) with the probability\n",
        "    # for each of the vocab_size character i need to use a categorical to choose the best\n",
        "    # then flatten the matrix into a list for evaluating\n",
        "    predicted_text = list(tf.random.categorical(x, num_samples=1).numpy())\n",
        "    x = np.concatenate(predicted_text).ravel().tolist()\n",
        "\n",
        "    # dividing the vector in verse\n",
        "    x_divided = divide_versi(x)\n",
        "    y_divided = divide_versi(y)\n",
        "\n",
        "    # extract the structure of the rhymes from generated and groud truth\n",
        "    x_rhymes = rhymes_extractor(x_divided)\n",
        "    y_rhymes = rhymes_extractor(y_divided)\n",
        "\n",
        "    # it returns me a list with the number of rhyming lines\n",
        "    # Example: [(1,3), (2,4)] means that lines 1 and 3 rhyme and that the\n",
        "    # lines 2 and 4 as well\n",
        "\n",
        "    # I create a vector of 1 for y because the rhymes are always there\n",
        "    y_bin = np.ones(max_rhymes, dtype='float32')\n",
        "    # I create a vector of 1 for the rhymes generated, I will put 0 if it rhyme\n",
        "    # Is NOT present in dante, discount with a 0.5 since there is at least the rhyme\n",
        "    x_bin = np.ones(max_rhymes, dtype='float32')\n",
        "\n",
        "    if x_rhymes == []:\n",
        "      x_bin = np.zeros(max_rhymes, dtype='float32')\n",
        "\n",
        "    # if the generated rhyme is in Dante's original rhymes then I sign it as valid\n",
        "    # I keep maximum max_ryhmes rhymes: I can because in 150-200 characters I don't have more than 5-6 lines\n",
        "    # so in Dante I would have 2 rhymes, I exceed 2 to help the network create even wrong rhymes\n",
        "    for i in range(max_rhymes+1):\n",
        "      if i < len(y_rhymes):\n",
        "        # check dante's rhyme with predicted rhymes, if it not exist set 0.0\n",
        "        if y_rhymes[i] not in x_rhymes:\n",
        "          x_bin[i] = 0.0\n",
        "        # check predicted rhyme with Dante's rhymes, if not exist set 0.5 to increase number of rhymes produced\n",
        "        if i < len(x_rhymes) and x_rhymes[i] not in y_rhymes:\n",
        "          x_bin[i] = 0.5\n",
        "\n",
        "    # concatenate vectors with rhyming encoding\n",
        "    x_bin_tot[v] = x_bin\n",
        "    y_bin_tot[v] = y_bin\n",
        "  \n",
        "  # MSE over vector\n",
        "  r = tf.keras.losses.mean_squared_error(y_bin_tot, x_bin_tot)\n",
        "\n",
        "  return np.mean(r)\n",
        "\n",
        "# NEW VERSION\n",
        "# creo un vettore con le rime di y reale e di y generato\n",
        "# Ex: in y reale se ho ABABC il vettore è [1,2,1,2,3] con o zero ad indicare nulla\n",
        "# per y generato devo creare un vettore di lunghezza uguale per poi valutarlo con una sparse_crossentropy\n",
        "# problema: non avrà mai le stesse righe\n",
        "\n",
        "# extract matrix of index of where the zeros are\n",
        "#tf.map_fn(fn=lambda t: t.map_fn(fn=lambda x: 1 if x == 0 else 0), elems=x_batch)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPjMSZOzh_60"
      },
      "source": [
        "# Model\n",
        "\n",
        "At this point, I can specify the RNN architecture with all its hyperparameters. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kiExaZj-iG1"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFZfbimYAkvk"
      },
      "source": [
        "# size of vocabulary\n",
        "vocab_size = len(char2idx)\n",
        "\n",
        "# size of mini batches during training\n",
        "batch_size = 100  # 100\n",
        "\n",
        "# size of training subset at each epoch\n",
        "subset_size = batch_size * 100\n",
        "\n",
        "# vector size of char embeddings\n",
        "embedding_size = 200  # 250\n",
        "\n",
        "lstm_unit_1 = 2048\n",
        "lstm_unit_2 = 4096\n",
        "\n",
        "# debug variables\n",
        "debug_model = False\n",
        "if debug_model:\n",
        "  lstm_unit_1 = 1024\n",
        "  lstm_unit_2 = 2048\n",
        "\n",
        "\n",
        "hidden_size = 300  # for Dense() layers 250\n",
        "\n",
        "n_epochs = 50\n",
        "\n",
        "learning_rate = 0.001  # 0.0001"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-LOqWfs06v3"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brY8sqvsD9h9"
      },
      "source": [
        "def perplexity(labels, logits):\n",
        "    \"\"\"Calculates perplexity metric = 2^(entropy) or e^(entropy)\"\"\"\n",
        "    return pow(2, loss(y_true=labels, y_pred=logits))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHDktX8rF2Iz"
      },
      "source": [
        "## Custom learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRTdMjQCvIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "12efa6c5-4d08-43b7-a25c-5976f466488e"
      },
      "source": [
        "#@title\n",
        "#learning_rate_tot = []\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=10):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step ** 1.5)\n",
        "    arg2 = step * ((self.warmup_steps+10) ** -1.3)\n",
        "    lr = tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    print(step)\n",
        "\n",
        "    return lr\n",
        "\n",
        "d_model = 500\n",
        "learning_rate_custom_1 = CustomSchedule(d_model)\n",
        "plt.plot(learning_rate(tf.range(50, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n",
        "\n",
        "\n",
        "learning_rate_custom_2 = tf.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=5,\n",
        "    decay_rate=0.80,\n",
        "    staircase=True)\n",
        "plt.plot(learning_rate(tf.range(50, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IS2bRMqCjhb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ng05biTbx6U"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Adamax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r22pA00o-fb7"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbtlhhW4bPyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1183d45-0955-49f4-909f-275fde444ccc"
      },
      "source": [
        "# Input Layer\n",
        "X = Input(shape=(None, ), batch_size=batch_size)\n",
        "\n",
        "# Embedding Layer\n",
        "embedded = Embedding(vocab_size, embedding_size, \n",
        "                     batch_input_shape=(batch_size, None), \n",
        "                     embeddings_regularizer=tf.keras.regularizers.L2()\n",
        "                     )(X)\n",
        "\n",
        "# Dense layer\n",
        "embedded = Dense(embedding_size, relu)(embedded)\n",
        "\n",
        "# First LSTM\n",
        "encoder_output, hidden_state, cell_state = LSTM(units=lstm_unit_1,\n",
        "                                                         return_sequences=True,\n",
        "                                                         return_state=True)(embedded)\n",
        "# Dropout\n",
        "encoder_output = Dropout(0.3)(encoder_output)\n",
        "# Dense layer\n",
        "encoder_output = Dense(embedding_size, activation='relu')(encoder_output)\n",
        "\n",
        "# Concat of first LSTM hidden state\n",
        "initial_state_double = [tf.concat([hidden_state, hidden_state], 1), tf.concat([hidden_state, hidden_state], 1)]\n",
        "\n",
        "# Second LSTM\n",
        "encoder_output, hidden_state, cell_state = LSTM(units=lstm_unit_2,\n",
        "                                                         return_sequences=True,\n",
        "                                                         return_state=True)(encoder_output, initial_state=initial_state_double)\n",
        "# Dropout\n",
        "encoder_output = Dropout(0.3)(encoder_output)\n",
        "# Dense layer\n",
        "encoder_output = Dense(hidden_size, activation='relu')(encoder_output)\n",
        "\n",
        "# Prediction Layer\n",
        "Y = Dense(units=vocab_size)(encoder_output)\n",
        "\n",
        "# Compile model\n",
        "model = Model(inputs=X, outputs=Y)\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), optimizer='adam', metrics=[perplexity, sparse_categorical_crossentropy])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(100, None)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (100, None, 200)     12800       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (100, None, 200)     40200       embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(100, None, 2048),  18423808    dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (100, None, 2048)    0           lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (100, None, 200)     409800      dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_16 (TFOpLambda)       (None, 4096)         0           lstm_16[0][1]                    \n",
            "                                                                 lstm_16[0][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_17 (TFOpLambda)       (None, 4096)         0           lstm_16[0][1]                    \n",
            "                                                                 lstm_16[0][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  [(100, None, 4096),  70402048    dense_33[0][0]                   \n",
            "                                                                 tf.concat_16[0][0]               \n",
            "                                                                 tf.concat_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (100, None, 4096)    0           lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (100, None, 300)     1229100     dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (100, None, 64)      19264       dense_34[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 90,537,020\n",
            "Trainable params: 90,537,020\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPcE1ZuK-mkS"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK1OwjD1IDD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e38b1d9-29c6-4e7d-a797-4558fbb6845c"
      },
      "source": [
        "def train_on_batch(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # returns a tensor with shape (batch_size, len_text)\n",
        "        x_predicted = model(x)\n",
        "\n",
        "        scce = tf.keras.losses.sparse_categorical_crossentropy(y, x_predicted, from_logits = True)\n",
        "        # we cant return a tensor with that shape so we return a float that are summed\n",
        "        custom = get_custom_loss(x_predicted, y)\n",
        "\n",
        "        current_loss = tf.reduce_mean(scce + custom)\n",
        "\n",
        "    gradients = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return current_loss, scce, custom\n",
        "\n",
        "\n",
        "loss_history = []\n",
        "custom_loss_history = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    # Take subsets of train and target\n",
        "    sample = np.random.randint(0, text_matrix.shape[0]-1, subset_size)\n",
        "    sample_train = text_matrix[ sample , : ]\n",
        "    sample_target = text_matrix[ sample+1 , : ]\n",
        "\n",
        "    for iteration in range(sample_train.shape[0] // batch_size):\n",
        "        take = iteration * batch_size\n",
        "        x = sample_train[ take:take+batch_size , : ]\n",
        "        y = sample_target[ take:take+batch_size , : ]\n",
        "\n",
        "        current_loss, scce, custom = train_on_batch(x, y)\n",
        "        loss_history.append(current_loss)\n",
        "        custom_loss_history.append(custom)\n",
        "    \n",
        "    print(\"{}.  \\t  Total-Loss: {%.2f}  \\t  Custom-Loss: {%.2f}  \\t Time: {} sec/epoch\".format(\n",
        "        epoch+1, current_loss.numpy(),custom, round(time.time()-start, 2)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.  \t  Total-Loss: 4.010016441345215  \t  Custom-Loss: 0.9637500047683716  \t Time: 293.47sec/epoch\n",
            "2.  \t  Total-Loss: 4.030500888824463  \t  Custom-Loss: 0.9756249785423279  \t Time: 307.06sec/epoch\n",
            "3.  \t  Total-Loss: 3.182433605194092  \t  Custom-Loss: 0.9568750262260437  \t Time: 312.95sec/epoch\n",
            "4.  \t  Total-Loss: 2.8650026321411133  \t  Custom-Loss: 0.9837499856948853  \t Time: 313.92sec/epoch\n",
            "5.  \t  Total-Loss: 2.609344720840454  \t  Custom-Loss: 0.9700000286102295  \t Time: 314.24sec/epoch\n",
            "6.  \t  Total-Loss: 2.517993688583374  \t  Custom-Loss: 0.9725000262260437  \t Time: 314.17sec/epoch\n",
            "7.  \t  Total-Loss: 2.4020440578460693  \t  Custom-Loss: 0.9524999856948853  \t Time: 313.59sec/epoch\n",
            "8.  \t  Total-Loss: 2.338041067123413  \t  Custom-Loss: 0.965624988079071  \t Time: 314.41sec/epoch\n",
            "9.  \t  Total-Loss: 2.2583961486816406  \t  Custom-Loss: 0.9237499833106995  \t Time: 314.22sec/epoch\n",
            "10.  \t  Total-Loss: 2.138793706893921  \t  Custom-Loss: 0.9087499976158142  \t Time: 314.07sec/epoch\n",
            "11.  \t  Total-Loss: 2.0700838565826416  \t  Custom-Loss: 0.903124988079071  \t Time: 314.33sec/epoch\n",
            "12.  \t  Total-Loss: 1.941026210784912  \t  Custom-Loss: 0.8656250238418579  \t Time: 313.65sec/epoch\n",
            "13.  \t  Total-Loss: 1.771570086479187  \t  Custom-Loss: 0.7818750143051147  \t Time: 314.66sec/epoch\n",
            "14.  \t  Total-Loss: 1.687868356704712  \t  Custom-Loss: 0.84375  \t Time: 314.26sec/epoch\n",
            "15.  \t  Total-Loss: 1.4826817512512207  \t  Custom-Loss: 0.7574999928474426  \t Time: 314.59sec/epoch\n",
            "16.  \t  Total-Loss: 1.2133463621139526  \t  Custom-Loss: 0.6000000238418579  \t Time: 314.0sec/epoch\n",
            "17.  \t  Total-Loss: 1.1144053936004639  \t  Custom-Loss: 0.6343749761581421  \t Time: 313.6sec/epoch\n",
            "18.  \t  Total-Loss: 0.8055357933044434  \t  Custom-Loss: 0.47562500834465027  \t Time: 314.18sec/epoch\n",
            "19.  \t  Total-Loss: 0.7007781267166138  \t  Custom-Loss: 0.390625  \t Time: 314.25sec/epoch\n",
            "20.  \t  Total-Loss: 0.5565990805625916  \t  Custom-Loss: 0.3162499964237213  \t Time: 313.75sec/epoch\n",
            "21.  \t  Total-Loss: 0.47247928380966187  \t  Custom-Loss: 0.2731249928474426  \t Time: 314.15sec/epoch\n",
            "22.  \t  Total-Loss: 0.49915868043899536  \t  Custom-Loss: 0.31937500834465027  \t Time: 313.9sec/epoch\n",
            "23.  \t  Total-Loss: 0.43105775117874146  \t  Custom-Loss: 0.25999999046325684  \t Time: 313.77sec/epoch\n",
            "24.  \t  Total-Loss: 0.39101776480674744  \t  Custom-Loss: 0.23749999701976776  \t Time: 313.38sec/epoch\n",
            "25.  \t  Total-Loss: 0.4077293276786804  \t  Custom-Loss: 0.2618750035762787  \t Time: 313.62sec/epoch\n",
            "26.  \t  Total-Loss: 0.320130854845047  \t  Custom-Loss: 0.18125000596046448  \t Time: 314.26sec/epoch\n",
            "27.  \t  Total-Loss: 0.3527769446372986  \t  Custom-Loss: 0.21437500417232513  \t Time: 313.77sec/epoch\n",
            "28.  \t  Total-Loss: 0.4172026813030243  \t  Custom-Loss: 0.2787500023841858  \t Time: 313.52sec/epoch\n",
            "29.  \t  Total-Loss: 0.38769757747650146  \t  Custom-Loss: 0.25187501311302185  \t Time: 313.12sec/epoch\n",
            "30.  \t  Total-Loss: 0.3396531045436859  \t  Custom-Loss: 0.203125  \t Time: 313.65sec/epoch\n",
            "31.  \t  Total-Loss: 0.35239896178245544  \t  Custom-Loss: 0.22499999403953552  \t Time: 313.57sec/epoch\n",
            "32.  \t  Total-Loss: 0.2829080820083618  \t  Custom-Loss: 0.15125000476837158  \t Time: 313.58sec/epoch\n",
            "33.  \t  Total-Loss: 0.3790247440338135  \t  Custom-Loss: 0.2462500035762787  \t Time: 313.43sec/epoch\n",
            "34.  \t  Total-Loss: 0.33667394518852234  \t  Custom-Loss: 0.20624999701976776  \t Time: 313.36sec/epoch\n",
            "35.  \t  Total-Loss: 0.26563942432403564  \t  Custom-Loss: 0.13500000536441803  \t Time: 312.82sec/epoch\n",
            "36.  \t  Total-Loss: 0.3471832275390625  \t  Custom-Loss: 0.2162500023841858  \t Time: 313.4sec/epoch\n",
            "37.  \t  Total-Loss: 0.3562263548374176  \t  Custom-Loss: 0.22812500596046448  \t Time: 312.77sec/epoch\n",
            "38.  \t  Total-Loss: 0.39930659532546997  \t  Custom-Loss: 0.26875001192092896  \t Time: 312.41sec/epoch\n",
            "39.  \t  Total-Loss: 0.3014850318431854  \t  Custom-Loss: 0.1706250011920929  \t Time: 312.86sec/epoch\n",
            "40.  \t  Total-Loss: 0.3754675090312958  \t  Custom-Loss: 0.25  \t Time: 313.01sec/epoch\n",
            "41.  \t  Total-Loss: 0.3421162962913513  \t  Custom-Loss: 0.21937499940395355  \t Time: 313.66sec/epoch\n",
            "42.  \t  Total-Loss: 0.3408163785934448  \t  Custom-Loss: 0.21437500417232513  \t Time: 313.4sec/epoch\n",
            "43.  \t  Total-Loss: 0.34843307733535767  \t  Custom-Loss: 0.22750000655651093  \t Time: 313.19sec/epoch\n",
            "44.  \t  Total-Loss: 0.34151941537857056  \t  Custom-Loss: 0.21875  \t Time: 313.24sec/epoch\n",
            "45.  \t  Total-Loss: 0.31275784969329834  \t  Custom-Loss: 0.1875  \t Time: 313.09sec/epoch\n",
            "46.  \t  Total-Loss: 0.3145294785499573  \t  Custom-Loss: 0.1899999976158142  \t Time: 312.8sec/epoch\n",
            "47.  \t  Total-Loss: 0.35340631008148193  \t  Custom-Loss: 0.2306250035762787  \t Time: 312.99sec/epoch\n",
            "48.  \t  Total-Loss: 0.34381377696990967  \t  Custom-Loss: 0.22499999403953552  \t Time: 312.95sec/epoch\n",
            "49.  \t  Total-Loss: 0.3517332375049591  \t  Custom-Loss: 0.22499999403953552  \t Time: 312.88sec/epoch\n",
            "50.  \t  Total-Loss: 0.31506821513175964  \t  Custom-Loss: 0.19062499701976776  \t Time: 313.29sec/epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWovlkWZ_28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "1fb18e8e-e6b7-4646-9133-c535021cea0c"
      },
      "source": [
        "model.save(\"deep_comedy_custom_loss_01.h5\")\n",
        "from google.colab import files\n",
        "files.download('deep_comedy_custom_loss_01.h5') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5336a0ec-b9aa-4a0b-83e6-6f979612592a\", \"deep_comedy_custom_loss_01.h5\", 97372192)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CS75-X9-TBd"
      },
      "source": [
        "## Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qArT0IfJ2M3M"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('time (s)')\n",
        "ax1.set_ylabel('exp', color=color)\n",
        "ax1.plot(loss_history, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('sin', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(custom_loss_history, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6uAhmV2Atth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dbbaf876-1b7c-4266-d46a-f5aaf2c84814"
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAnothsm80Fj"
      },
      "source": [
        "## Saved model\n",
        "file name, len_matrix, batch_size, embedding_size, lstm_1_unit, lstm_2_unit, hidden_unit, epochs, learning_rate\n",
        "\n",
        "model_custom_loss_01.h5: 150,100, 200, 2048,4096,300,50,0.001 BASE MODEL\n",
        "\n",
        "model_custom_loss_02.h5: 150,**150**, 200, 2048,4096,300,50,0.001\n",
        "\n",
        "model_custom_loss_03.h5: 150,100, 200, 2048,4096,300,50,**custom_exponential**\n",
        "\n",
        "model_custom_loss_04.h5: 150,**150**, 200, 2048,4096,300,50,**custom_exponential**\n",
        "\n",
        "model_custom_loss_05.h5: **200**,150, 200, 2048,4096,300,50,0.001\n",
        "\n",
        "model_custom_loss_06.h5: **100**,150, 200, 2048,4096,300,50,0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrMdonRckAWB"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "At this point, let's check how the model generates text. In order to do it, I must make some changes to my RNN architecture above.\n",
        "\n",
        "First, I must change the fixed batch size. After training, I want to feed just one sentence into my Network to make it continue the character sequence. I will feed a string into the model, make it predict the next character, update the input sequence, and repeat the process until a long generated text is obtained. Because of this, the succession of input sequences is now different from training session, in which portions of text were sampled randomly. I now have to set `stateufl = True` in the `LSTM()` layer, so that each LSTM cell will keep in memory the internal state from the previous sequence. With this I hope the model will better remember sequential information while generating text.\n",
        "\n",
        "I will instantiate a new `generator` RNN with these new features, and transfer the trained weights of my `RNN` into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyS28-ZAEcxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d1a120-1822-4952-c689-020409115826"
      },
      "source": [
        "# Input Layer\n",
        "X = Input(shape=(None, ), batch_size=1)\n",
        "embedded = Embedding(vocab_size, embedding_size)(X)\n",
        "embedded = Dense(embedding_size, relu)(embedded)\n",
        "encoder_output, hidden_state, cell_state = LSTM(units=lstm_unit_1,\n",
        "                                                         return_sequences=True,\n",
        "                                                         return_state=True,\n",
        "                                              stateful=True)(embedded)\n",
        "encoder_output = Dropout(0.3)(encoder_output)\n",
        "encoder_output = Dense(embedding_size, activation='relu')(encoder_output)\n",
        "\n",
        "initial_state_double = [tf.concat([hidden_state, hidden_state], 1), tf.concat([hidden_state, hidden_state], 1)]\n",
        "encoder_output, hidden_state, cell_state = LSTM(units=lstm_unit_2,\n",
        "                                                         return_sequences=True,\n",
        "                                                         return_state=True,\n",
        "                                                stateful=True)(encoder_output, initial_state=initial_state_double)\n",
        "encoder_output = Dropout(0.3)(encoder_output)\n",
        "encoder_output = Dense(hidden_size, activation='relu')(encoder_output)\n",
        "\n",
        "Y = Dense(units=vocab_size)(encoder_output)\n",
        "\n",
        "# Compile model\n",
        "generator = Model(inputs=X, outputs=Y)\n",
        "generator.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), optimizer='adam', metrics=[perplexity, sparse_categorical_crossentropy])\n",
        "print(generator.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(1, None)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (1, None, 200)       12400       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (1, None, 200)       40200       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(1, None, 2048), (1 18423808    dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (1, None, 2048)      0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (1, None, 200)       409800      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (1, 4096)            0           lstm[0][1]                       \n",
            "                                                                 lstm[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_1 (TFOpLambda)        (1, 4096)            0           lstm[0][1]                       \n",
            "                                                                 lstm[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(1, None, 4096), (1 70402048    dense_1[0][0]                    \n",
            "                                                                 tf.concat[0][0]                  \n",
            "                                                                 tf.concat_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (1, None, 4096)      0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (1, None, 300)       1229100     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (1, None, 62)        18662       dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 90,536,018\n",
            "Trainable params: 90,536,018\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whB1azhVAtrp"
      },
      "source": [
        "# Import trained weights from RNN to generator\n",
        "load_file = True\n",
        "if load_file:\n",
        "  generator.load_weights(\"deep_comedy_custom_loss_01.h5\")\n",
        "else:\n",
        "  generator.set_weights(model.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE2hYSqAAtkn"
      },
      "source": [
        "def generate_text(start_string, model, num_generate = 1000, temperature = 1.0):\n",
        "    \n",
        "    # Vectorize input string\n",
        "    input_eval = [char2idx[s] for s in start_string]  \n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    \n",
        "    text_generated = [] # List to append predicted chars \n",
        "    \n",
        "    idx2char = { v: k for k, v in char2idx.items() }  # invert char-index mapping\n",
        "    \n",
        "    model.reset_states()\n",
        "    \n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        \n",
        "        # sample next char based on distribution and temperature\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        \n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "        \n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_NWeo1fAtiC"
      },
      "source": [
        "# Let's feed the first lines:\n",
        "start_string = \"\"\"\n",
        "Nel mezzo del cammin di nostra vita\n",
        "mi ritrovai per una selva oscura,\n",
        "chè la diritta via era smarrita.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for t in [0.1, 0.2, 0.2, 0.5, 1.0]:\n",
        "    print(\"####### TEXT GENERATION - temperature = {}\\n\".format(t))\n",
        "    print(generate_text(start_string, generator, num_generate = 1000, temperature = t))\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XVUs8zgC5mF",
        "outputId": "6ae7dbf4-799f-42be-8293-2f69abd1cfa8"
      },
      "source": [
        "print(\"FINISCHED\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISCHED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed-aAA291bUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69392861-9729-4e99-c519-facd3733290f"
      },
      "source": [
        "# Exam mode for 1 Canto so 33 terzine\n",
        "start_inferno = \"\"\"\n",
        "Nel mezzo del cammin di nostra vita\n",
        "mi ritrovai per una selva oscura,\n",
        "chè la diritta via era smarrita.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "start_purgatorio = \"\"\"\n",
        "Per correr miglior acque alza le vele\n",
        "omai la navicella del mio ingegno,\n",
        "che lascia dietro a se mar si crudele;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "start_paradiso = \"\"\"\n",
        "La gloria di colui che tutto move\n",
        "per l'universo penetra, e risplende\n",
        "in una parte più e meno altrove.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(generate_text(start_string = start_purgatorio, num_generate = 1000, temperature = 0.1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Per correr miglior acque alza le vele\n",
            "omai la navicella del mio ingegno,\n",
            "che lascia dietro a se mar si crudele;\n",
            "\n",
            "e canterò di quel secondo regno\n",
            "dove l'umano spirito si purga\n",
            "e di salire al ciel diventa degno. \n",
            "\n",
            "Ma qui la morta poesì resurga,\n",
            "o sante Muse, poi che vostro sono;\n",
            "e qui Caliopè alquanto surga, \n",
            "\n",
            "seguitando il mio canto con quel suono\n",
            "di cui le Piche misere sentiro\n",
            "lo colpo tal, che disperar perdono. \n",
            "\n",
            "Dolce color d'oriental zaffiro,\n",
            "che s'accogliendo il carro e la vergogna\n",
            "per la mia morte, e per la mesta salusfa\n",
            "o da prova che riceve il sole e 'l verno, \n",
            "\n",
            "per la ragion che di', quinci si parte\n",
            "verso settentrion, quanto li Ebrei\n",
            "vedevan lui verso la calda parte. \n",
            "\n",
            "Ma se a te piace, volontier saprei\n",
            "quanto avemo ad andar; ché 'l poggio sale\n",
            "più che salir non posson li occhi miei\". \n",
            "\n",
            "Ed elli a me: \"Se tu segui tua stella,\n",
            "non puoi fallire a glorioso porto,\n",
            "se ben m'accorsi ne la vita bella; \n",
            "\n",
            "e s'io non fossi sì per tempo morto,\n",
            "veggendo il cielo a te così benigno,\n",
            "dato t'avrei a l'opera conforto. \n",
            "\n",
            "Ma quelle dolci volle esser devota,\n",
            "e lasciar sedea tutta rive tramma. \n",
            "\n",
            "E per vente vo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbXuy2OopudL"
      },
      "source": [
        "# NEW IDEAS\n",
        "\n",
        "#### Training:\n",
        "*   Cross validation\n",
        "*   Insert Rhyme as feature to learn as haiku\n",
        "*   Use syllable as input and not word\n",
        "*   Different training on different dataset\n",
        "* Use categorical_crossentropy instead of sparse_ but with one-hot encoded inputs\n",
        "* Symbols for explicit start and end terzina\n",
        "* training as classificator for structure: like \"these two world are rhymes\" or \"this is a endecasillable and this not\" or \"this is a terzina and this not\" then generation\n",
        "* use dropout \n",
        "* use two lstm\n",
        "* \n",
        "\n",
        "#### Presentation\n",
        "* graphs over the vocabulary like distribution of used words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7hZnK6wpy0j"
      },
      "source": [
        "RNN = Sequential([\n",
        "    Embedding(vocab_size, embedding_size,\n",
        "              batch_input_shape=(batch_size, None)),\n",
        "              \n",
        "    Dense(embedding_size, activation = relu),\n",
        "    \n",
        "    LSTM(len_input, return_sequences = True),\n",
        "\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Dense(hidden_size, activation = relu), \n",
        "\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Dense(vocab_size)\n",
        "])\n",
        "\n",
        "RNN.summary()\n",
        "\n",
        "generator = Sequential([\n",
        "    Embedding(vocab_size, embedding_size,batch_input_shape=(1, None)),\n",
        "\n",
        "    Dense(embedding_size, activation = relu),\n",
        "    \n",
        "    LSTM(len_input, return_sequences = True, stateful=True),\n",
        "\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Dense(hidden_size, activation = relu), \n",
        "\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Dense(vocab_size)\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSpzyH2BaG4"
      },
      "source": [
        "#@title\n",
        "#@DEBUG CUSTOM LOSS\n",
        "\n",
        "x = [[49, 46, 36, 44, 49, 32, 48, 36,  1, 45,  1, 35, 51, 36,  1, 45,  1, 50,\n",
        " 48, 36,  1, 46, 36, 48,  1, 49, 36, 30,  5,  0, 44, 45, 44,  1, 42, 32,\n",
        "  1, 37, 45, 48, 50, 51, 44, 32,  1, 35, 40,  1, 46, 48, 40, 43, 32,  1,\n",
        " 52, 32, 34, 32, 44, 50, 36,  5,  0, 44, 45, 44,  1, 35, 36, 34, 40, 43,\n",
        " 32, 49,  5,  1, 47, 51, 32, 36,  1, 49, 51, 44, 50,  1, 46, 32, 51, 46,\n",
        " 36, 48, 51, 43,  1, 14, 36, 40,  5,  1,  0,  0, 32, 35, 35, 40, 43, 32,\n",
        " 44, 35, 60,  5,  1, 43, 32,  1, 34, 45, 44, 50, 48, 45,  1, 32, 42,  1,\n",
        " 43, 45, 44, 35, 45,  1, 36, 48, 48, 32, 44, 50, 36,  0, 42, 40, 34, 36,\n",
        " 44, 55, 32,  1, 35, 40], \n",
        " [42,  1, 34, 45, 44, 49, 40, 38, 42, 40, 45,  1, 44, 36, 42,  1, 47, 51,\n",
        " 32, 42, 36,  1, 45, 38, 44, 36,  1, 32, 49, 46, 36, 50, 50, 45,  0, 34,\n",
        " 48, 36, 32, 50, 45,  1, 58,  1, 52, 40, 44, 50, 45,  1, 46, 48, 40, 32,\n",
        "  1, 34, 39, 36,  1, 52, 32, 35, 32,  1, 32, 42,  1, 37, 45, 44, 35, 45,\n",
        "  5,  1,  0,  0, 46, 36, 48, 60,  1, 34, 39, 36,  1, 32, 44, 35, 32, 49,\n",
        " 49, 36,  1, 52, 36, 48,  4,  1, 42, 45,  1, 49, 51, 45,  1, 35, 40, 42,\n",
        " 36, 50, 50, 45,  0, 42, 32,  1, 49, 46, 45, 49, 32,  1, 35, 40,  1, 34,\n",
        " 45, 42, 51, 40,  1, 34, 39,  4, 32, 35,  1, 32, 42, 50, 36,  1, 38, 48,\n",
        " 40, 35, 32,  0, 35, 40,]]\n",
        "y = [[46, 36, 44, 49, 32, 48, 36,  1, 45,  1, 35, 51, 36,  1, 45,  1, 50, 48,\n",
        " 36,  1, 46, 36, 48,  1, 49, 36, 40,  5,  0, 44, 45, 44,  1, 42, 32,  1,\n",
        " 37, 45, 48, 50, 51, 44, 32,  1, 35, 40,  1, 46, 48, 40, 43, 32,  1, 52,\n",
        " 32, 34, 32, 44, 50, 36,  5,  0, 44, 45, 44,  1, 35, 36, 34, 40, 43, 32,\n",
        " 49,  5,  1, 47, 51, 32, 36,  1, 49, 51, 44, 50,  1, 46, 32, 51, 46, 36,\n",
        " 48, 51, 43,  1, 14, 36, 40,  5,  1,  0,  0, 32, 35, 35, 40, 43, 32, 44,\n",
        " 35, 60,  5,  1, 43, 32,  1, 34, 45, 44, 50, 48, 45,  1, 32, 42,  1, 43,\n",
        " 45, 44, 35, 45,  1, 36, 48, 48, 32, 44, 50, 36,  0, 42, 40, 34, 36, 44,\n",
        " 55, 32,  1, 35, 40,  1], [ 1, 34, 45, 44, 49, 40, 38, 42, 40, 45,  1, 44, 36, 42,  1, 47, 51, 32,\n",
        " 42, 36,  1, 45, 38, 44, 36,  1, 32, 49, 46, 36, 50, 50, 45,  0, 34, 48,\n",
        " 36, 32, 50, 45,  1, 58,  1, 52, 40, 44, 50, 45,  1, 46, 48, 40, 32,  1,\n",
        " 34, 39, 36,  1, 52, 32, 35, 32,  1, 32, 42,  1, 37, 45, 44, 35, 45,  5,\n",
        "  1,  0,  0, 46, 36, 48, 60,  1, 34, 39, 36,  1, 32, 44, 35, 32, 49, 49,\n",
        " 36,  1, 52, 36, 48,  4,  1, 42, 45,  1, 49, 51, 45,  1, 35, 40, 42, 36,\n",
        " 50, 50, 45,  0, 42, 32,  1, 49, 46, 45, 49, 32,  1, 35, 40,  1, 34, 45,\n",
        " 42, 51, 40,  1, 34, 39,  4, 32, 35,  1, 32, 42, 50, 36,  1, 38, 48, 40,\n",
        " 35, 32,  0, 35, 40, 49,] ]\n",
        "\n",
        "'''\n",
        "EXPERIMENT\n",
        "CUSTOM LOSS\n",
        "'''\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "def divide_versi(y):\n",
        "  doppiozero = False\n",
        "\n",
        "  y_divided = [[]]\n",
        "  for ly in y:\n",
        "    ly = int(ly)\n",
        "\n",
        "    # devo pulire la lista dai segni di punteggiatura, \n",
        "    # in chartoidx significa i numeri da 1 a 10 compresi.\n",
        "    if ly in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:  # con i Tensor non funziona\n",
        "    # if ly is 1 or ly is 2 or ly is 3 or ly is 4 or ly is 5 or ly is 6 or ly is 7 \\\n",
        "    #     or ly is 8 or ly is 9 or ly is 10:\n",
        "        continue\n",
        "    else:\n",
        "      # se è zero vuol dire \\n quindi aggiungo una nuova riga\n",
        "      if ly is 0:\n",
        "        if not doppiozero:\n",
        "          y_divided.append([])\n",
        "        doppiozero = True\n",
        "        continue\n",
        "\n",
        "      y_divided[-1].append(ly)\n",
        "      doppiozero = False\n",
        "\n",
        "  if y_divided is not []:\n",
        "    if y[-1] != 0:\n",
        "      # dato che l'ultima riga non finisce con 0 vuol dire che è incompleta e la rimuovo\n",
        "      y_divided.pop()\n",
        "\n",
        "  # i need to re check because maybe i pop the only one\n",
        "  if len(y_divided) != 0:\n",
        "    if len(y_divided[0]) < 3:\n",
        "      # se la prima riga è minore di 4 non posso farci nulla quindi la elimino\n",
        "      y_divided.pop(0)\n",
        "\n",
        "  return y_divided\n",
        "\n",
        "def rhymes_extractor(y_divided):\n",
        "  # estraggo lo schema di rime da y\n",
        "  rhymes = []\n",
        "  for i in range(len(y_divided)):\n",
        "    # con la fine del verso (ultime due lettere) controllo se le altre righe \n",
        "    # finiscono con le stesse lettere\n",
        "    vy = y_divided[i]\n",
        "\n",
        "    last_word_1 = vy[-2:]\n",
        "\n",
        "    # ABA BCB CDC\n",
        "\n",
        "    # devo controllare se la riga i fa rima con la riga i+2 \n",
        "    if i+2 < len(y_divided):\n",
        "      next_vy = y_divided[i+2]\n",
        "      # print(vy[-2:])\n",
        "      # print(next_vy[-2:])\n",
        "      if last_word_1 == next_vy[-2:]:\n",
        "        rhymes.append((i, i+2))\n",
        "    \n",
        "    if i+4 < len(y_divided):\n",
        "      # print(vy[-2:])\n",
        "      # print(next_vy[-2:])\n",
        "      next_vy = y_divided[i+4]\n",
        "      if last_word_1 == next_vy[-2:]:\n",
        "        rhymes.append((i, i+4))\n",
        "\n",
        "  # print(rhymes)\n",
        "  return rhymes\n",
        "\n",
        "\n",
        "def get_custom_loss(x_batch, y_batch):\n",
        "  summed_custom_loss = 0\n",
        "  # x_batch ha lo shape (200, 200) quindi ho 200 vettori con 200 lettere ognuno\n",
        "  # le 200 lettere sono le feature\n",
        "\n",
        "  # max numero di rime possibili (arbitrario)\n",
        "  max_rhymes = 4\n",
        "\n",
        "  print(\"Shape di x_batch e y_batch\")\n",
        "  print((len(x_batch), len(x_batch[0])))\n",
        "  print((len(y_batch), len(y_batch[0])))\n",
        "\n",
        "  x_bin_tot = np.ones(shape=(len(x_batch), max_rhymes), dtype='float32')\n",
        "  y_bin_tot = np.ones(shape=(len(x_batch), max_rhymes), dtype='float32')\n",
        "\n",
        "  # scorro i 200 vettori\n",
        "  # for (x, y) in zip(x_batch, y_batch):  # Non funziona con i tensori\n",
        "  for v in range(len(x_batch)):\n",
        "    x = x_batch[v]\n",
        "    y = y_batch[v]\n",
        "\n",
        "    # given that the model returns a matrix with shape (150, 62) with the probability\n",
        "    # for each of the 62 character i need to use a categorical to choose the best\n",
        "    # then flatten the matrix into a list for evaluating\n",
        "    predicted_text = list(tf.random.categorical(x, num_samples=1).numpy())\n",
        "    x = np.concatenate(predicted_text).ravel().tolist()\n",
        "\n",
        "    # dividio il vettore in versi utili\n",
        "    x_divided = divide_versi(x)\n",
        "    y_divided = divide_versi(y)\n",
        "\n",
        "    print(\"Divisione in versi di x_batch e y_batch\")\n",
        "    print(x_divided)\n",
        "    print(y_divided)\n",
        "\n",
        "    # assicuro che il numero di versi siano uguali\n",
        "    # !!! non posso perchè il generato può avere errori e quindi, per esempio,\n",
        "    # avere più o meno versi\n",
        "    # assert len(x_divided) == len(y_divided)\n",
        "\n",
        "    # estraggo lo schema di rime\n",
        "    x_rhymes = rhymes_extractor(x_divided)\n",
        "    y_rhymes = rhymes_extractor(y_divided)\n",
        "\n",
        "    print(\"Rime dei versi di x_batch e y_batch\")\n",
        "    print(x_rhymes)\n",
        "    print(y_rhymes)\n",
        "\n",
        "    # mi ritorna una lista con il numero delle righe che fanno rima\n",
        "    # Esempio: [(1,3), (2,4)] significa che le righe 1 e 3 fanno rima e che le \n",
        "    # righe 2 e 4 pure \n",
        "    # TODO se avessimo due terzine intere si potrebbe valutare rime a 3 righe [aBaBcB]\n",
        "\n",
        "    # creo un vettore di 1 per la y perchè le rime ci sono sempre\n",
        "    y_bin = np.ones(max_rhymes, dtype='float32')\n",
        "    # creo un vettore di 1 per le rime generate, metterò 0 se la rima \n",
        "    # NON è presente in dante, abbuono con uno 0.5 visto che c'è la rima almeno\n",
        "    x_bin = np.ones(max_rhymes, dtype='float32')\n",
        "\n",
        "    if x_rhymes == []:\n",
        "      x_bin = np.zeros(max_rhymes, dtype='float32')\n",
        "\n",
        "    # se la rima generata è nelle rime originali di Dante allora la segno come valida\n",
        "    # tengo massimo max_ryhmes rime: posso perchè in 150-200 caratteri non ho più di 5-6 righe\n",
        "    # quindi in Dante avrei 2 rime, eccedo di 2 per aiutare la rete a creare rime anche sbagliate\n",
        "    for i in range(max_rhymes+1):\n",
        "      if i < len(x_rhymes):\n",
        "        if y_rhymes[i] not in x_rhymes:\n",
        "          x_bin[i] = 0.\n",
        "        if x_rhymes[i] not in y_rhymes:\n",
        "          x_bin[i] = 0.5\n",
        "\n",
        "    print(\"Vettore che rappresenta il confronto delle rime tra il generato e Dante dei versi di x_batch e y_batch \\n y è sempre 1 mentre il generato ha 1 se la rima c'è in dante o 0.5 se non c'è \")\n",
        "    print(x_bin)\n",
        "    print(y_bin)\n",
        "      \n",
        "    # concateno i vettori con l'encoding delle rime\n",
        "    x_bin_tot[v] = x_bin\n",
        "    y_bin_tot[v] = y_bin\n",
        "\n",
        "  print(\"Matrice dei vettori su cui eseguo la MSE: (x,y)\")\n",
        "  print(x_bin_tot)\n",
        "  print(y_bin_tot)\n",
        "  r = tf.keras.losses.mean_squared_error(y_bin_tot, x_bin_tot)\n",
        "\n",
        "  print(\"Risultato della MSE:\")\n",
        "  print(r)\n",
        "\n",
        "  print(\"Loss finale fatta con la media della MSE\")\n",
        "  print(np.mean(r))\n",
        "  # MSE sui vettori\n",
        "  return np.mean(r)\n",
        "\n",
        "\n",
        "\n",
        "debug_loss = True\n",
        "custom_loss = get_custom_loss(x,y)\n",
        "print(custom_loss)\n",
        "\n",
        "# NEW VERSION\n",
        "# creo un vettore con le rime di y reale e di y generato\n",
        "# Ex: in y reale se ho ABABC il vettore è [1,2,1,2,3] con o zero ad indicare nulla\n",
        "# per y generato devo creare un vettore di lunghezza uguale per poi valutarlo con una sparse_crossentropy\n",
        "# problema: non avrà mai le stesse righe\n",
        "\n",
        "# extract matrix of index of where the zeros are\n",
        "#tf.map_fn(fn=lambda t: t.map_fn(fn=lambda x: 1 if x == 0 else 0), elems=x_batch)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}