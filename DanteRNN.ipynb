{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "Recursive Neural Network(RNN) for generating the Divina Commedia of Dante Alighieri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,  CSVLogger\n",
    "from keras.layers import Add, Dense, Input, LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from models import Generator2, create_training_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform char in integer\n",
    "def numerical_encoding(text, char_dict):\n",
    "    \"\"\" Text to list of chars, to np.array of numerical idx \"\"\"\n",
    "    chars_list = [ char for char in text ]\n",
    "    chars_list = [ char_dict[char] for char in chars_list ]\n",
    "    chars_list = np.array(chars_list)\n",
    "    return chars_list\n",
    "\n",
    "\n",
    "def get_text_matrix(sequence, len_input):\n",
    "    \n",
    "    # create empty matrix\n",
    "    X = np.empty((len(sequence)-len_input, len_input))\n",
    "    \n",
    "    # fill each row/time window from input sequence\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i,:] = sequence[i : i+len_input]\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# Percent of samples to use for training, might be necessary if you're running out of memory\n",
    "sample_size = 1\n",
    "\n",
    "# The latent dimension of the LSTM\n",
    "latent_dim = 2048\n",
    "\n",
    "# Number of epochs to train for\n",
    "epochs = 20\n",
    "\n",
    "# path of the data\n",
    "data_path = 'data/DivinaCommedia.csv'\n",
    "\n",
    "name = 'all_data_test_2'\n",
    "output_dir = Path('output_%s' % name)\n",
    "output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(str(data_path))\n",
    "df = df.sample(frac=sample_size)\n",
    "\n",
    "\n",
    "max_line_length = int(max([df['%s' % i].astype(str).str.len().quantile(.99) for i in range(3)]))\n",
    "\n",
    "df = df[\n",
    "    (df['0'].astype(str).str.len() <= max_line_length) & \n",
    "    (df['1'].astype(str).str.len() <= max_line_length) & \n",
    "    (df['2'].astype(str).str.len() <= max_line_length)\n",
    "].copy()\n",
    "\n",
    "# preprocessing data\n",
    "# Pad the lines to the max line length with new lines\n",
    "for i in range(3):\n",
    "    # For input, duplicate the first character\n",
    "    # TODO - Why?\n",
    "    df['%s_in' % i] = (df[str(i)].str[0] + df[str(i)]).str.pad(max_line_length+2, 'right', '\\n')\n",
    "    \n",
    "    # \n",
    "    #df['%s_out' % i] = df[str(i)].str.pad(max_line_len, 'right', '\\n') + ('\\n' if i == 2 else df[str(i+1)].str[0])\n",
    "    \n",
    "    # TODO - trying to add the next line's first character before the line breaks\n",
    "    if i == 2: # If it's the last line\n",
    "        df['%s_out' % i] = df[str(i)].str.pad(max_line_length+2, 'right', '\\n')\n",
    "    else: \n",
    "        # If it's the first or second line, add the first character of the next line to the end of this line.\n",
    "        # This helps with training so that the next RNN has a better chance of getting the first character right.\n",
    "        df['%s_out' % i] = (df[str(i)] + '\\n' + df[str(i+1)].str[0]).str.pad(max_line_length+2, 'right', '\\n')\n",
    "    \n",
    "max_line_length += 2\n",
    "\n",
    "inputs = df[['0_in', '1_in', '2_in']].values\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(filters='', char_level=True)\n",
    "tokenizer.fit_on_texts(inputs.flatten())\n",
    "n_tokens = len(tokenizer.word_counts) + 1\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "# X is the input for each line in sequences of one-hot-encoded values\n",
    "X = np_utils.to_categorical([\n",
    "  tokenizer.texts_to_sequences(inputs[:,i]) for i in range(3)\n",
    "  ], num_classes=n_tokens)\n",
    "\n",
    "outputs = df[['0_out', '1_out', '2_out']].values\n",
    "\n",
    "# Y is the output for each line in sequences of one-hot-encoded values\n",
    "Y = np_utils.to_categorical([\n",
    "    tokenizer.texts_to_sequences(outputs[:,i]) for i in range(3)\n",
    "], num_classes=n_tokens)\n",
    "\n",
    "# X_syllables is the count of syllables for each line\n",
    "X_syllables = df[['0_syllables', '1_syllables', '2_syllables']].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model, lstm, lines, inputs, outputs = create_training_model(latent_dim, n_tokens)\n",
    "\n",
    "filepath = str(output_dir / (\"%s-{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\" % latent_dim))\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "csv_logger = CSVLogger(str(output_dir / 'training_log.csv'), append=True, separator=',')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger]\n",
    "\n",
    "training_model.fit([\n",
    "    X[0], X_syllables[:,0],\n",
    "    X[1], X_syllables[:,1], \n",
    "    X[2], X_syllables[:,2]\n",
    "], [Y[0], Y[1], Y[2]], batch_size=64, epochs=epochs, validation_split=.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Joblib\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Load a copy of the training model from disk by creating a new model using the same parameters and then loading the weights.\n",
    "\n",
    "output_dir = Path('output_all_data_test_2')\n",
    "\n",
    "# Get the parameters used for creating the model\n",
    "#latent_dim, n_tokens, max_line_length, tokenizer = joblib.load(output_dir / 'metadata.pkl')\n",
    "\n",
    "# Create the new placeholder model\n",
    "training_model, lstm, lines, inputs, outputs = create_training_model(latent_dim, n_tokens)\n",
    "\n",
    "# Load the specified weights\n",
    "training_model.load_weights(output_dir / '2048-20-1.32-4.88.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator using the training model as the template\n",
    "\n",
    "generator = Generator2(lstm, lines, tokenizer, n_tokens, max_line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    generator.generate_haiku([11, 11, 11])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    generator.generate_haiku(temperature=.3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    generator.generate_haiku(temperature=.5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    generator.generate_haiku(temperature=.75)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    generator.generate_haiku(temperature=1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
